


from google.colab import drive


drive.mount('/content/drive')


get_ipython().getoutput("cat /content/drive/MyDrive/ML/iris/iris.names")


import pandas as pd


get_ipython().getoutput("ls /content/drive/MyDrive/ML/iris")


get_ipython().getoutput("cat /content/drive/MyDrive/ML/iris/iris.data")


import matplotlib.pyplot as plt





path = '/content/drive/MyDrive/ML/iris/iris.data'
df = pd.read_csv(path, header=None, names=['sepal_length','sepal_width','petal_length','petal_width','class'])


print(df['class'].value_counts())


df = df.dropna()


df = df[df['class'].astype(str).str.len() > 0]





print("Unique count:", df['sepal_length'].nunique())
print(df['sepal_length'].describe())





plt.figure()
plt.scatter(df.index, df['sepal_length'], s=18)
plt.xlabel('Sample index')          # numer próbki
plt.ylabel('sepal_length (cm)')     # wartość sepal length
plt.title('Iris: sepal_length vs sample index')
plt.show()








setosa = df[df['class'] == 'Iris-setosa'].copy()


bins   = [-float('inf'), 2.5, 3.0, 3.5]
labels = ['<2.5', '2.5–3.0', '3.0–3.5']


setosa['sw_bin'] = pd.cut(setosa['sepal_width'], bins=bins, labels=labels, right=False)


counts = setosa['sw_bin'].value_counts().reindex(labels, fill_value=0)
print(counts)


plt.figure()
counts.plot(kind='bar')
plt.xlabel('sepal_width bin')
plt.ylabel('count')
plt.title('Iris-setosa: counts by sepal_width bins')
plt.show()








pl = df['petal_length'].to_numpy()
sizes = 30 + 170 * (pl - pl.min()) / (pl.max() - pl.min() + 1e-9)

palette = {
    'Iris-setosa':    'tab:blue',
    'Iris-versicolor':'tab:orange',
    'Iris-virginica': 'tab:green'
}

plt.figure()
for cls, sub in df.groupby('class'):
    plt.scatter(sub['sepal_length'], sub['sepal_width'],
                s=sizes[sub.index], alpha=0.8, label=cls, c=palette.get(cls, 'gray'))

plt.xlabel('sepal_length (cm)')
plt.ylabel('sepal_width (cm)')
plt.title('Iris: sepal_length vs sepal_width (size ∝ petal_length)')
plt.legend()
plt.show()








from itertools import combinations

pl = df['petal_length'].to_numpy()
sizes = 30 + 90 * (pl - pl.min()) / (pl.max() - pl.min() + 1e-9)

features = ['sepal_length','sepal_width','petal_length','petal_width']
pairs = list(combinations(features, 2))

fig, axes = plt.subplots(2, 3, figsize=(14, 8))
axes = axes.ravel()

for ax, (x, y) in zip(axes, pairs):
    for cls, sub in df.groupby('class'):
        ax.scatter(sub[x], sub[y],
                   s=sizes[sub.index], alpha=0.8,
                   c=palette.get(cls, 'gray'), label=cls)
    ax.set_xlabel(x.replace('_', ' '))
    ax.set_ylabel(y.replace('_', ' '))
    ax.set_title(f'{x} vs {y}')

handles, labels = axes[0].get_legend_handles_labels()
fig.legend(handles, labels, loc='upper center', ncol=3, frameon=False)

plt.tight_layout(rect=(0,0,1,0.95))
plt.show()





get_ipython().getoutput("pip -q install seaborn")


import seaborn as sns


features = ['sepal_length','sepal_width','petal_length','petal_width']

# Long format for seaborn: one column with feature name, one with value
long_df = df.melt(
    id_vars='class',
    value_vars=features,
    var_name='feature',
    value_name='value'
)

sns.set_theme(style="whitegrid")

g = sns.catplot(
    data=long_df,
    x='class', y='value',
    col='feature',            # one subplot per feature
    kind='violin',
    inner='quartile',         # draw median and quartiles inside violins
    height=4, aspect=0.9,
    sharey=False,             # each subplot gets its own y-scale
    cut=0                     # don't extend beyond the data range
)

g.set_axis_labels("class", "value")
for ax in g.axes.flat:
    ax.tick_params(axis='x', rotation=15)
    ax.set_title(ax.get_title().replace('feature = ', ''))

plt.tight_layout()
plt.show()











get_ipython().getoutput("cat /content/drive/MyDrive/ML/bank/bank-names.txt")


get_ipython().getoutput("cat /content/drive/MyDrive/ML/bank-additional/bank-additional-names.txt")





df = pd.read_csv('/content/drive/MyDrive/ML/bank/bank-full.csv', sep=';')
df[['duration','y']].head()


df = df.dropna(subset=['duration','y'])
df['duration'] = pd.to_numeric(df['duration'], errors='coerce')
df = df.dropna(subset=['duration'])


import numpy as np

bins = np.arange(0, df['duration'].max()+50, 50) # Common binning


fig, axes = plt.subplots(1, 3, figsize=(16,4), sharey=True)

# (a) all data
axes[0].hist(df['duration'], bins=bins)
axes[0].set_title('All: duration')
axes[0].set_xlabel('duration [s]')
axes[0].set_ylabel('count')

# (b) y = no
axes[1].hist(df.loc[df['y']=='no','duration'], bins=bins)
axes[1].set_title('y = no')
axes[1].set_xlabel('duration [s]')

# (c) y = yes
axes[2].hist(df.loc[df['y']=='yes','duration'], bins=bins)
axes[2].set_title('y = yes')
axes[2].set_xlabel('duration [s]')

plt.tight_layout()
plt.show()


print(df['duration'].max())





sub = df.loc[df['age'] > 25, 'balance'].dropna()

plt.figure()
plt.hist(sub, bins=40)
plt.xlabel('balance')
plt.ylabel('count')
plt.title('Histogram balance (age > 25)')
plt.show()


get_ipython().getoutput("pip -q install ipywidgets")


from ipywidgets import interact, IntSlider

def hist_by_age(age_min=26):
    s = df.loc[df['age'] > age_min, 'balance'].dropna()
    plt.figure(figsize=(5,3))
    plt.hist(s, bins=30)
    plt.xlabel('balance')
    plt.ylabel('count')
    plt.title(f'balance for age > {age_min}')
    plt.tight_layout()
    plt.show()

interact(hist_by_age, age_min=IntSlider(value=26, min=18, max=100, step=1, description='Min age'));





t = 360
sub = df[df['duration'] > t]
pct_yes_t = (sub['y'] == 'yes').mean() * 100
print(f'Procent pozytywnych dla t={t}: {pct_yes_t:.2f}%')


thresholds = np.arange(0, 1801, 60)
percents = []

for t in thresholds:
    sub = df[df['duration'] > t]
    if len(sub) == 0:
        percents.append(np.nan)
    else:
        percents.append((sub['y'] == 'yes').mean() * 100)

plt.figure(figsize=(6,3.5))
plt.plot(thresholds, percents, marker='o')
plt.xlabel('threshold t (duration > t, seconds)')
plt.ylabel('% positive (y = yes)')
plt.title('Share of positives vs call-duration threshold')
plt.tight_layout()
plt.show()








thresholds = np.linspace(df['balance'].min(), df['balance'].max(), 30)
percents = []

for t in thresholds:
    sub = df[df['balance'] > t]
    percents.append((sub['y'] == 'yes').mean() * 100 if len(sub) else np.nan)

base = (df['y'] == 'yes').mean() * 100  # poziom bazowy (losowe wybieranie)

plt.figure(figsize=(6,3.5))
plt.plot(thresholds, percents, marker='o')
plt.axhline(base, linestyle='--')  # linia bazowa do porównania
plt.xlabel('threshold t (balance > t)')
plt.ylabel('% positive (y = yes)')
plt.title('Share of positives vs balance threshold')
plt.tight_layout()
plt.show()








data = df[['balance','y']].dropna().sample(frac=1, random_state=0)
n = len(data)//2
train = data.iloc[:n]
test  = data.iloc[n:]


# progi: 30 kwantyli salda (bez skrajnego 1% ogona)
thresholds = np.quantile(train['balance'], np.linspace(0.0, 0.99, 30))

# % yes wśród klientów z balance > t (wykres z pkt 4 na train)
pct_yes = []
for t in thresholds:
    sub = train[train['balance'] > t]
    pct_yes.append((sub['y'] == 'yes').mean() * 100 if len(sub) else np.nan)

# wybór progu t* (punkt równych błędów warunkowych na train)
def errors_conditional(df_part, t):
    pred_pos = df_part['balance'] > t
    fp = (df_part.loc[pred_pos, 'y'] != 'yes').mean() * 100 if pred_pos.any() else np.nan
    fn = (df_part.loc[df_part['y']=='yes', 'balance'] <= t).mean() * 100 if (df_part['y']=='yes').any() else np.nan
    return fp, fn

fp_tr, fn_tr = [], []
for t in thresholds:
    fp, fn = errors_conditional(train, t)
    fp_tr.append(fp)
    fn_tr.append(fn)

idx_equal = int(np.nanargmin(np.abs(np.array(fp_tr) - np.array(fn_tr))))
t_star = thresholds[idx_equal]
print(f'Wybrany próg (train): t* = {t_star:.2f}')

# wykres z pkt 4 (train): % yes vs próg + linia bazowa + zaznaczone t*
plt.figure(figsize=(6,3.5))
plt.plot(thresholds, pct_yes, marker='o')
base = (train['y'] == 'yes').mean() * 100
plt.axhline(base, linestyle='--')
plt.axvline(t_star, linestyle=':', color='k')
plt.xlabel('threshold t (balance > t)')
plt.ylabel('% yes among balance > t (train)')
plt.tight_layout()
plt.show()


fp_te, fn_te = [], []
for t in thresholds:
    fp, fn = errors_conditional(test, t)
    fp_te.append(fp); fn_te.append(fn)

plt.figure(figsize=(6,3.5))
plt.plot(thresholds, fp_tr, label='FP (train)')
plt.plot(thresholds, fn_tr, label='FN (train)')
plt.plot(thresholds, fp_te, '--', label='FP (test)')
plt.plot(thresholds, fn_te, '--', label='FN (test)')
plt.axvline(t_star, linestyle=':', color='k', label=f't*={t_star:.0f}')
plt.xlabel('threshold t (balance > t ⇒ predict yes)')
plt.ylabel('error [%] (conditional)')
plt.legend()
plt.tight_layout()
plt.show()

# błędy dokładnie w t* (dla jasności)
fp_tr_star, fn_tr_star = errors_conditional(train, t_star)
fp_te_star, fn_te_star = errors_conditional(test,  t_star)
print(f'train @ t*: FP={fp_tr_star:.2f}%, FN={fn_tr_star:.2f}%')
print(f'test  @ t*: FP={fp_te_star:.2f}%, FN={fn_te_star:.2f}%')








get_ipython().getoutput("cat /content/drive/MyDrive/ML/car+evaluation/car.names")


get_ipython().getoutput("cat /content/drive/MyDrive/ML/car+evaluation/car.data")


df = pd.read_csv('/content/drive/MyDrive/ML/car+evaluation/car.data', header=None, names=["buying","maint","doors","persons","lug_boot","safety","class"])





order = ["unacc","acc","good","vgood"]
counts = df["class"].value_counts().reindex(order).fillna(0)

# wykres tortowy
plt.figure(figsize=(5,5))
plt.pie(counts, labels=order, autopct="%1.1f%%", startangle=90)
plt.title("Car Evaluation — udział klas jakości")
plt.show()





df_234 = df[df['doors'].isin(['2','3','4'])]

ct = pd.crosstab(df_234['safety'], df_234['doors'])

counts = ct.reindex(index=['low','med','high'],
                    columns=['2','3','4'],
                    fill_value=0)

x = np.arange(len(counts.index)); w = 0.25
fig, ax = plt.subplots(figsize=(6,3.5))
ax.bar(x - w, counts['2'].values, w, label='2 doors')
ax.bar(x     , counts['3'].values, w, label='3 doors')
ax.bar(x + w, counts['4'].values, w, label='4 doors')
ax.set_xticks(x); ax.set_xticklabels(counts.index)
ax.set_xlabel('safety'); ax.set_ylabel('count')
ax.set_title('Doors count by safety class')
ax.legend(); plt.tight_layout(); plt.show()


pd.crosstab(df_234['safety'], df_234['doors'])








attrs = ["buying","maint","doors","persons","lug_boot"]

# mapowanie kategorii -> liczby
maps = {
    "buying":  {"low":1, "med":2, "high":3, "vhigh":4},
    "maint":   {"low":1, "med":2, "high":3, "vhigh":4},
    "doors":   {"2":2, "3":3, "4":4, "5more":5},
    "persons": {"2":2, "4":4, "more":5},
    "lug_boot":{"small":1, "med":2, "big":3},
}

row = df.iloc[0][attrs]

values = [maps[a][row[a]] for a in attrs]

angles = np.linspace(0, 2*np.pi, len(attrs), endpoint=False)
values += values[:1]
angles = np.concatenate([angles, angles[:1]])

plt.figure()
ax = plt.subplot(111, polar=True)
ax.plot(angles, values, marker='o')
ax.fill(angles, values, alpha=0.25)
ax.set_xticks(angles[:-1])
ax.set_xticklabels(attrs)
ax.set_title("Car radar (single record)", pad=20)
max_r = int(np.ceil(max(values)))
ax.set_ylim(0, max_r)
ax.set_rticks(np.arange(0, max_r + 1))
plt.show()





y_true = df['class'].isin(['good','vgood'])

# predykcja według reguły 'safety, buying, maint' >>> 'lug_boot' >>> reszta
y_pred = (
    (df['safety'] == 'high') &
    (df['buying'].isin(['low','med'])) &
    (df['maint'].isin(['low','med'])) &
    (df['lug_boot'].isin(['med','big']))
)

acc = (y_true == y_pred).mean() * 100
fp = ((y_pred) & (~y_true)).sum()   # przewidzieliśmy TAK, ale w rzeczywistości NIE
fn = ((~y_pred) & (y_true)).sum()   # przewidzieliśmy NIE, ale w rzeczywistości TAK
tp = ((y_pred) & (y_true)).sum()
tn = ((~y_pred) & (~y_true)).sum()
print(f"Accuracy: {acc:.1f}%  |  TP={tp}, FP={fp}, FN={fn}, TN={tn}")

counts = pd.Series({'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn})
plt.figure(figsize=(5,3))
plt.bar(counts.index, counts.values)
plt.ylabel('count')
plt.title('Rule outcomes (errors highlighted)')
plt.tight_layout()
plt.show()








x = np.random.randn(1_000_000)

plt.figure(figsize=(6,3.5))
plt.hist(x, bins=100)
plt.xlabel('wartość')
plt.ylabel('liczność')
plt.title('Histogram N(0,1) — 1e6 próbek')
plt.tight_layout()
plt.show()





# histogram w skali gęstości (pole ≈ 1)
plt.figure(figsize=(6,3.5))
plt.hist(x, bins=100, density=True, alpha=0.6, label='histogram (density)')

# teoretyczna gęstość N(0,1): φ(z) = (1/√(2π)) * exp(-z²/2)
z = np.linspace(-4, 4, 400)
pdf = (1/np.sqrt(2*np.pi)) * np.exp(-0.5*z**2)
plt.plot(z, pdf, linewidth=2, label='PDF N(0,1)')

plt.xlabel('wartość')
plt.ylabel('gęstość')
plt.title('Histogram vs gęstość N(0,1)')
plt.legend()
plt.tight_layout()
plt.show()





path = '/content/drive/MyDrive/ML/iris/iris.data'
df = pd.read_csv(path, header=None, names=['sepal_length','sepal_width','petal_length','petal_width','class'])
df = df.dropna()
df = df[df['class'].astype(str).str.len() > 0]


s = 0.25
np.random.seed(0)
df_noisy = df.copy()
df_noisy['sepal_length_n'] = df_noisy['sepal_length'] + np.random.normal(0, s, len(df_noisy))
df_noisy['sepal_width_n']  = df_noisy['sepal_width']  + np.random.normal(0, s, len(df_noisy))

colors = df_noisy['class'].map({'Iris-setosa':'tab:blue',
                                'Iris-versicolor':'tab:orange',
                                'Iris-virginica':'tab:green'})

sizes = 20 + 60*(df_noisy['petal_length'] - df_noisy['petal_length'].min())/(
                df_noisy['petal_length'].max() - df_noisy['petal_length'].min())

plt.figure(figsize=(6,4))
plt.scatter(df_noisy['sepal_length_n'], df_noisy['sepal_width_n'],
            c=colors, s=sizes, alpha=0.8, edgecolor='none')
plt.xlabel('sepal_length (noisy)')
plt.ylabel('sepal_width (noisy)')
plt.title(f'Iris: sepal_length vs sepal_width  (noise s={s})')
plt.tight_layout()
plt.show()











np.random.seed(0)
X = np.random.randn(1_000_000, 2)   # kolumny: X[:,0]=x, X[:,1]=y

bins = 60
H, xedges, yedges = np.histogram2d(X[:,0], X[:,1], bins=bins, range=[[-4,4],[-4,4]])

from mpl_toolkits.mplot3d import Axes3D # tylko aktywacja 3d plt

xcent = (xedges[:-1] + xedges[1:]) / 2
ycent = (yedges[:-1] + yedges[1:]) / 2
Xc, Yc = np.meshgrid(xcent, ycent, indexing='ij')

dx = (xedges[1] - xedges[0]) * np.ones_like(H.ravel())
dy = (yedges[1] - yedges[0]) * np.ones_like(H.ravel())
dz = H.ravel()

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.bar3d(
    Xc.ravel(), Yc.ravel(), np.zeros_like(dz),
    dx*np.ones_like(dz), dy*np.ones_like(dz), dz,
    color='steelblue',
    shade=True,
    edgecolor=(0,0,0,0.15),
    linewidth=0.2,
    alpha=1.0
)
ax.set_xlabel('x'); ax.set_ylabel('y'); ax.set_zlabel('count')
ax.set_title('3D histogram: 2D normal N((0,0), I)')
plt.tight_layout()
plt.show()





get_ipython().getoutput("pip -q install plotly")

import plotly.graph_objects as go

# 1) Histogram 2D → gęstość (pole = 1)
bins = 60
lim = 4
H, xedges, yedges = np.histogram2d(
    X[:,0], X[:,1], bins=bins, range=[[-lim, lim], [-lim, lim]]
)
bin_area = (xedges[1]-xedges[0]) * (yedges[1]-yedges[0])
H_density = H / (len(X) * bin_area)  # przeskaluj z „count” do gęstości

xcent = (xedges[:-1] + xedges[1:]) / 2
ycent = (yedges[:-1] + yedges[1:]) / 2
Xc, Yc = np.meshgrid(xcent, ycent, indexing='ij')

# teoretyczna gęstość N((0,0), I): 1/(2π) * exp(-0.5*(x^2+y^2))
Z = (1/(2*np.pi)) * np.exp(-0.5*(Xc**2 + Yc**2))

fig = go.Figure()
fig.add_surface(x=Xc, y=Yc, z=H_density, colorscale='Blues',
                opacity=0.95, showscale=False, name='histogram (density)')
fig.add_surface(x=Xc, y=Yc, z=Z, colorscale='Reds',
                name='PDF N((0,0), I)', opacity=0.40, showscale=False)

fig.update_layout(
    title='2D normal — histogram (density) vs theoretical PDF',
    scene=dict(
        xaxis_title='x', yaxis_title='y', zaxis_title='density',
        aspectmode='manual', aspectratio=dict(x=1, y=1, z=0.6)
    ),
    legend=dict(y=0.9)
)
fig.show()



